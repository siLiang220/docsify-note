
## 双向同步


新老DB通过binlog双向数据同步，保障新老数据准实时最终一致，保障可灰度、可回滚，新老系统业务逻辑完全不感知灰度状态。同时因为全新设计的新的数据模型和老系统数据模型有很大的差异，同步逻辑要做差异转换

![](https://zhaosi-1253759587.cos.ap-nanjing.myqcloud.com/files/obsidian/picture/20231026193941.png)

## 回环问题

数据双向同步就带来数据回环的问题，通常大家熟知的数据传输服务，比如A-B 两个库相互同步，一般是监听到A有事务同步到B，在写入B库的同时也在事务中增加一个固定标识，那么数据传输服务监听到B的事务时会判断一下是否有此固定标识，如果有就不再同步到A了。

但是我们通过监听canal消息只能获得到最新的数据，在A产生一个binlog，同步到B之后也会产生一个新的binlog，如果仍然同步这条binlog的话，就可能产生无限循环。最后我们主要总结如下三类循环为例： 

### 数据更新产生循环

如下图，此为典型的数据回环，如果不加以处理，seq_1 会无限循环更新下去 
![](https://zhaosi-1253759587.cos.ap-nanjing.myqcloud.com/files/obsidian/picture/20231026194130.png)

解决方案：

我们的方案是所有需要同步的表我们新增字段 
```sql
sync_time` timestamp(3) NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '同步判断时间';
```

当监听到binlog消息后我们会判断binlog消息中的sync_time 是否大于当前数据的 sync_time，如果大于执行更新 
```sql
update user_reg_origin set guest=?,join_ip=?,join_time=?,ctime=?,mtime=?,sync_time=? where mid=? and sync_time<?; 
```

### 插入/删除产生循环： 
在短时间内出现一次插入和删除操作，如果insert的消息没有同步结束，这个时候立即删除数据就可能会出现新、旧库不断插入、删除的无限循环。如下图，第2步如果监听的新库的insert seq_1 消息时，旧库数据已经被删除，那么再次插入就能插入成功，然后又会同步到已被删除的新库，出现循环 

![](https://zhaosi-1253759587.cos.ap-nanjing.myqcloud.com/files/obsidian/picture/20231026194505.png)

解决方案：

我们把每一条binlog都作为一条数据变更消息，这条消息处理完成之后增加redis一个标识，监听一条binlog消息后，我们查询反方向这条消息是否被处理过，如果被处理过就直接丢弃，如下图 
![](https://zhaosi-1253759587.cos.ap-nanjing.myqcloud.com/files/obsidian/picture/20231026195026.png)

### 新系统软删除旧系统硬删除、新系统硬删除旧系统软删除产生的循环 

因为在执行更新操作同步的时候发现如果没有数据，我们就把更新之后的数据进行插入操作，如果瞬间再来一次删除，那么就会出现类似上面“插入/删除”循环的场景。

解决方案：

我们把软删除操作转换成对应delete和insert操作，后续策略和“插入/删除产生循环”解决方案一致 

## 数据核对 

为了及时发现新老系统数据不一致，我们增加了核对逻辑，主要有两种

数据变动增量核对：监听binlog消息，然后查询新、老库数据是否一致

查询接口返回核对：针对关键接口查询时会查询新老系统，进行比对

核对不一致的数据我们通过监控告警及时发现，但是考虑到数据修复的风险，我们并没有做自动修复，而是通过人工确认之后手工修复数据 